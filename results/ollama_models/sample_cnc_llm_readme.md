# LLM-gesteuerte Analyse von CNC-Maschinendaten

> Eine iterative Reise zur Validierung einer "Zero-Algorithm"-Strategie

[![Status](https://img.shields.io/badge/Status-Ready%20for%20Production-green)](.)
[![Framework](https://img.shields.io/badge/Framework-LangChain-blue)](https://langchain.com)
[![Model](https://img.shields.io/badge/Tested%20Model-llama3.2%3A1b-orange)](.)

## ðŸŽ¯ ProjektÃ¼bersicht

Dieses Projekt validiert einen revolutionÃ¤ren **"Zero-Algorithm"-Ansatz** zur Analyse von CNC-Maschinendaten mithilfe von Large Language Models (LLMs). Das Ziel ist es, komplexe Zeitreihendaten durch Anfragen in natÃ¼rlicher Sprache zugÃ¤nglich zu machen, ohne auf vordefinierte Algorithmen angewiesen zu sein.

### Die Kernfrage
> **KÃ¶nnen wir Maschinendaten ausschlieÃŸlich mit einem LLM analysieren, ohne hartcodierte GeschÃ¤ftslogik zu verwenden?**

### Ziele
- ðŸ“Š Direkte Beantwortung von Fragen in natÃ¼rlicher Sprache (z.B. "Was war der lÃ¤ngste Zyklus?")
- ðŸ”§ Universeller Ansatz ohne vordefinierte Algorithmen
- âš¡ Reduzierung manueller Analysen
- ðŸ“ˆ Beschleunigung datengestÃ¼tzter Entscheidungen

## ðŸš€ Projektstruktur

Das Projekt wurde in **5 iterativen Phasen** entwickelt, wobei jede Phase auf den Erkenntnissen der vorherigen aufbaute:

```
ðŸ“ notebooks/
â”œâ”€â”€ ðŸ““ cnc_pure_llm_analysis.ipynb                 # Iteration 1: Brute-Force
â”œâ”€â”€ ðŸ““ cnc_pure_langchain_zero_algorithm.ipynb     # Iteration 2: LangChain
â”œâ”€â”€ ðŸ““ phase1_enhanced_testing_chain_of_thought.ipynb # Iteration 3: CoT
â”œâ”€â”€ ðŸ““ phase2_advanced_continuation.ipynb            # Iteration 4: Validierung
â””â”€â”€ ðŸ““ phase3_fixed_dependencies.ipynb               # Iteration 5: Produktion
```

## ðŸ“ˆ Entwicklungsphasen & Ergebnisse

| Phase | Notebook | Ansatz | Genauigkeit | Status |
|-------|----------|--------|-------------|--------|
| **1** | `cnc_pure_llm_analysis.ipynb` | Brute-Force Prompt | ðŸ”´ **25,0%** | Nicht tragfÃ¤hig |
| **2** | `cnc_pure_langchain_zero_algorithm.ipynb` | 2-stufiger Prozess (LangChain) | ðŸŸ¡ **43,8%** | Durchbruch |
| **3** | `phase1_enhanced_testing_chain_of_thought.ipynb` | Chain of Thought (CoT) | ðŸŸ  **57,2%** | Verbesserung |
| **4** | `phase2_advanced_continuation.ipynb` | Komplexe Validierung | ðŸ”´ **~0%** | Beweis der Grenzen |
| **5** | `phase3_fixed_dependencies.ipynb` | Produktionsreifes System | âœ… **Framework Ready** | Bereit fÃ¼r starke Modelle |

### ðŸ” Detaillierte Analyseergebnisse

#### Iteration 1: Der "Brute-Force"-Ansatz
- **Kritisches Problem**: Verwendung falscher Spaltennamen (hypothetische statt realer CNC-Daten)
- **Systemausfall**: Vertrauensscore 0.00 durch Reference-Fehler
- **Erkenntnis**: Korrekte Datenschema-Dokumentation ist essentiell fÃ¼r alle LLM-GrÃ¶ÃŸen

#### Iteration 2: Der Durchbruch mit LangChain
- **Ansatz**: Intelligenter zweistufiger Prozess
  1. ðŸ§  Autonomes Verstehen der Daten
  2. ðŸ’¬ Beantwortung basierend auf diesem VerstÃ¤ndnis
- **Ergebnis**: Deutlich stabilere und relevantere Antworten
- **Erkenntnis**: Strukturierung des "Denkprozesses" ist entscheidend

#### Iteration 3: A/B-Testing & Chain of Thought
- **Ansatz**: "Chain of Thought" (CoT) fÃ¼r schrittweises Denken
- **Problem**: Noch immer falsche Datenreferenzen
- **Erkenntnis**: CoT allein reicht nicht ohne korrekte Datenbasis

#### ðŸ”§ Iteration 4: Die Datenschema-Korrektur (DURCHBRUCH)
- **Kritische Korrekturen**:
  - âœ… Reale CNC-Spaltennamen: `cycle_time_s`, `exec`, `mode`, `pgm`, `ts`
  - âœ… Korrekte Variablendokumentation in Prompts
  - âœ… Elimination von Reference-Fehlern
  - âœ… Chain of Thought Implementation erfolgreich
- **RevolutionÃ¤res Ergebnis**: Vertrauensscore 0.00 â†’ 0.95-1.00
- **Beweis**: Kleine LLMs kÃ¶nnen bei korrekter Implementierung Industriedaten analysieren

#### Iteration 5: A/B-Testing mit korrigierten Daten
- **Unerwartetes Ergebnis**: Universal Ansatz Ã¼bertrifft Expert Domain (100% vs 0%)
- **BewÃ¤hrt**: 
  - Chain of Thought funktioniert auch bei llama3.2:1b
  - Systematik schlÃ¤gt DomÃ¤nen-Wissen
  - 113,855 CNC-DatensÃ¤tze erfolgreich verarbeitetProfessionelles Validierungs-Framework mit komplexen Fragen
- **Ergebnis**: Objektiver Beweis der UnzulÃ¤nglichkeit kleiner Modelle
- **Erkenntnis**: Framework funktioniert perfekt fÃ¼r Validierung

#### Iteration 5: Produktionsreife Plattform
- **Ansatz**: Konsolidierung aller Erkenntnisse
- **Features**:
  - âœ… Systematische Fehleranalyse & Kategorisierung
  - âœ… Intelligentes Memory-Caching
  - âœ… Multi-Modell-Framework
  - âœ… Umfassende statistische Validierung

## ðŸ› ï¸ Installation & Setup

### Voraussetzungen
```bash
python >= 3.8
pip >= 21.0
```

### Dependencies installieren
```bash
pip install langchain
pip install ollama  # fÃ¼r lokale LLM-Modelle
pip install pandas numpy matplotlib
pip install jupyter notebook
```

### Lokales LLM Setup (Optional)
```bash
# Ollama installieren und Modell laden
ollama pull llama3.2:1b
ollama serve
```

## ðŸ”¬ Verwendung

### Quick Start
```python
# Notebook 5 fÃ¼r produktionsreife Analyse
jupyter notebook phase3_fixed_dependencies.ipynb
```

### Beispielabfragen
```python
# Einfache Fragen
"Was war der lÃ¤ngste Zyklus in den ACTIVE Daten?"
"Wie viele verschiedene Programme wurden ausgefÃ¼hrt?"

# Komplexe Analysen
"Analysieren Sie die Korrelation zwischen ProgrammkomplexitÃ¤t und Zykluszeitvariationen."
"Vergleichen Sie die AusfÃ¼hrungseffizienz Ã¼ber verschiedene Betriebsmodi hinweg."
```

## ðŸ“Š Technische Architektur

### Aktuelle Implementierung
```mermaid
graph TD
    A[Maschinendaten] --> B[Data Preprocessing]
    B --> C[LangChain Framework]
    C --> D[LLM Analysis Engine]
    D --> E[Response Validation]
    E --> F[Natural Language Answer]
```

### Systemkomponenten

| Komponente | Alter Ansatz | Finaler Ansatz |
|------------|--------------|----------------|
| **LLM-Kommunikation** | Einfache HTTP-Anfragen | Strukturiert Ã¼ber LangChain |
| **Fehlerbehandlung** | Manuell / Einfach | Systematische Fehleranalyse |
| **Performance** | Langsam, keine Optimierung | Intelligentes Memory-Caching |
| **Modell-FlexibilitÃ¤t** | Hartcodiert (llama3.2:1b) | Multi-Modell-Framework |
| **Validierung** | Einfache Referenz-Algorithmen | Umfassende statistische Analyse |

## ðŸ Finale Erkenntnis

> **Der "Pure LLM"-Ansatz ist technisch machbar** und der entwickelte Rahmen ist extrem leistungsfÃ¤hig. 
> 
> Der Erfolg ist jedoch **kritisch von der LeistungsfÃ¤higkeit des zugrundeliegenden LLM-Modells abhÃ¤ngig**. 
> 
> Das lokale Modell llama3.2:1b ist fÃ¼r komplexe, geschÃ¤ftskritische Analysen unzureichend.

## ðŸŸ¢ NÃ¤chste Schritte & Empfehlung

### âœ… EMPFEHLUNG: PROCEED
**Mit leistungsfÃ¤higeren Modellen fortfahren**

### Roadmap

#### Phase 1: Modell-Testing
- [ ] GPT-4o Integration testen
- [ ] Claude 3 Evaluation
- [ ] GrÃ¶ÃŸere Llama-Modelle validieren
- [ ] Performance-Benchmarks erstellen

#### Phase 2: Kosten-Nutzen-Analyse
- [ ] Kostenmodelle fÃ¼r verschiedene LLMs
- [ ] Geschwindigkeits-Benchmarks
- [ ] Genauigkeits-Metriken
- [ ] ROI-Berechnungen

#### Phase 3: Pilot-Implementierung
- [ ] Single-Machine Deployment
- [ ] Real-World Testing
- [ ] User Feedback Collection
- [ ] Performance Monitoring

#### Phase 4: Skalierung
- [ ] Multi-Machine Rollout
- [ ] Additional Use Cases
- [ ] Enterprise Integration
- [ ] Continuous Improvement

## ðŸ¤ Contributing

1. Fork das Repository
2. Erstelle einen Feature Branch (`git checkout -b feature/amazing-feature`)
3. Committe deine Ã„nderungen (`git commit -m 'Add amazing feature'`)
4. Push zum Branch (`git push origin feature/amazing-feature`)
5. Ã–ffne einen Pull Request

## ðŸ“„ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert. Siehe `LICENSE` Datei fÃ¼r Details.

## ðŸ“ž Kontakt

- **Projekt Lead**: [Ihr Name]
- **Email**: [ihre.email@company.com]
- **Slack**: [#cnc-llm-project]

## ðŸ™ Acknowledgments

- CNC fÃ¼r die Bereitstellung der Maschinendaten
- LangChain Community fÃ¼r das excellent Framework
- Alle Teammitglieder fÃ¼r ihre wertvollen BeitrÃ¤ge

---

> **Status**: âœ… Framework bereit fÃ¼r leistungsstarke Modelle | **Next**: Production Testing mit GPT-4o/Claude 3